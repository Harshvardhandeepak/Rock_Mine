# -*- coding: utf-8 -*-
"""Rock_vs_Mine_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kYJ7iSPGw2lUGAYJygGHTrv6c7xyMsOo

Importing Dependencies
"""

#for numerical data
import numpy as np
#for structures and dataframe
import pandas as pd
#for train_test split
from sklearn.model_selection import train_test_split
#model selection
from sklearn.linear_model import LogisticRegression
#accuracy score
from sklearn.metrics import accuracy_score

"""Data Collection and Data Processing"""

#loading dataset
#header is used to give s.no to the columns as their is not s.no in original dataset
sonar_data = pd.read_csv('/sonar data.csv', header = None)

#showing the first 5 rows to dataset
sonar_data.head()

#total no of rows and columns in a dataset
sonar_data.shape

#knowing the statistical measures
sonar_data.describe()

#finding total no of Mines and Rocks value
sonar_data[60].value_counts()

#taking mean value of each column
sonar_data.groupby(60).mean()

# separating features and labels
#features - all the numerical values
#labels - last column Rock and Mine value
X = sonar_data.drop(columns = 60, axis = 1) #droping the 60 column
Y = sonar_data[60] #adding 60 column

print(X)

print(Y)

"""Training and Testing Data

"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, stratify=Y, random_state=1)
#tst_size =0.1 means that 10% of data will be in used for testing rest for training
#stratify=Y is used to split rock and mine values equally
#random_state = 1 means that data will split in same manner whoever will use 1, we can also use 2

print(X.shape, X_train.shape, X_test.shape)

"""Model Training"""

model = LogisticRegression()
 #using logistic regression because data is binary classification

#traing the model
model.fit(X_train, Y_train)

"""Model Evaluation"""

#accuracy on training Data
X_train_prediction = model.predict(X_train) #prediction of our model
training_data_accuracy = accuracy_score(X_train_prediction, Y_train) #Y_train is real

print("Accuracy on training  data : ",training_data_accuracy)

#accuracy on test data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print('Accuracy on test data : ',test_data_accuracy)

"""Making a Predictive System"""

#for the putting the data
input_data = (0.0094,0.0333,0.0306,0.0376,0.1296,0.1795,0.1909,0.1692,0.1870,0.1725,0.2228,0.3106,0.4144,0.5157,0.5369,0.5107,0.6441,0.7326,0.8164,0.8856,0.9891,1.0000,0.8750,0.8631,0.9074,0.8674,0.7750,0.6600,0.5615,0.4016,0.2331,0.1164,0.1095,0.0431,0.0619,0.1956,0.2120,0.3242,0.4102,0.2939,0.1911,0.1702,0.1010,0.1512,0.1427,0.1097,0.1173,0.0972,0.0703,0.0281,0.0216,0.0153,0.0112,0.0241,0.0164,0.0055,0.0078,0.0055,0.0091,0.0067)
#changing the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

#reshape the np array as we are predicting for one instance, this converts a flat array to a 2D array with 1 row and appropriate no of columns.
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)
# 1 means 1 row
# -1 tells the Numpy to figure out the correct number of columns automatically

prediction = model.predict(input_data_reshaped)
print(prediction)

if (prediction[0]=='R'):
  print('It is a Rock')
else:
  print('It is a Mine')

